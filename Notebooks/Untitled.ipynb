{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1e951d77-0ee0-4320-8e8b-4fd739711728",
   "metadata": {},
   "source": [
    "# GAN_PI data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e4c1c928-c7d8-4487-9046-18288c742b3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scipy\n",
      "  Downloading scipy-1.15.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
      "Requirement already satisfied: numpy<2.5,>=1.23.5 in /dolfinx-env/lib/python3.12/site-packages (from scipy) (2.0.2)\n",
      "Downloading scipy-1.15.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (40.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.2/40.2 MB\u001b[0m \u001b[31m30.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: scipy\n",
      "Successfully installed scipy-1.15.1\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4865e9b0-c759-451f-a019-96d5da1ef942",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e701d86b-911d-45e9-a0ff-5d75b9c3c1ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Buckley_Swc_0_Sor_0_M_2.mat  burgers_shock.mat\n"
     ]
    }
   ],
   "source": [
    "!ls ../../gan-pi/resources/data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0d3e095b-b0b1-4647-bbb8-1ba25d61a593",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_lib = os.path.dirname(os.getcwd())\n",
    "path_resources = os.path.join(\"../../gan-pi\", 'resources')\n",
    "path_data = os.path.join(path_resources, 'data')\n",
    "\n",
    "filename = 'Buckley_Swc_0_Sor_0_M_2.mat'\n",
    "path_file = os.path.join(path_data, filename)\n",
    "data = scipy.io.loadmat(path_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1788d435-03f2-4f1a-ab17-3e6c9c4e6e6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['__header__', '__version__', '__globals__', 't', 'usol', 'x'])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5ef545e8-222a-45b6-8207-391ea7be37a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "256"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data[\"usol\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grandient example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[1., 1., 1.]],\n",
      "\n",
      "        [[1., 1., 1.]],\n",
      "\n",
      "        [[1., 1., 1.]]], requires_grad=True)\n",
      "tensor([[[1.0000, 1.8415, 0.5403, 1.0000]],\n",
      "\n",
      "        [[1.0000, 1.8415, 0.5403, 1.0000]],\n",
      "\n",
      "        [[1.0000, 1.8415, 0.5403, 1.0000]]], grad_fn=<StackBackward0>)\n",
      "torch.Size([3, 1, 4])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([[[0.1585, 2.5403, 0.0000]],\n",
       " \n",
       "         [[0.1585, 2.5403, 0.0000]],\n",
       " \n",
       "         [[0.1585, 2.5403, 0.0000]]], grad_fn=<AddBackward0>),)"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1 = torch.ones((3,1,3)).requires_grad_(True)  #\n",
    "print(x1)\n",
    "\n",
    "u1 = torch.stack([\n",
    "    x1[:,:,0]**0.5,\n",
    "    torch.sin(x1[:,:,1])+x1[:,:,0]**0.5,\n",
    "    torch.cos(x1[:,:,0]),\n",
    "    x1[:,:,1]**2,\n",
    "    ],axis=2)\n",
    "\n",
    "#u1 = torch.matmul(M,x1)\n",
    "\n",
    "\n",
    "#u1=torch.sin(torch.matmul(torch.rand(2,2).requires_grad_(True),x1))\n",
    "print(u1)\n",
    "print(u1.shape)\n",
    "torch.autograd.grad(\n",
    "    u1,x1,\n",
    "            grad_outputs=torch.ones_like(u1).to(u1.device),\n",
    "            create_graph=True,\n",
    "            retain_graph=True,\n",
    "            allow_unused=True\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Jacobian computation\n",
    "\n",
    "Expressed in pytorch with torch.autograd.grad\n",
    "\n",
    "$$ \\textbf{u} \\in \\mathbb{R}^n \\\\ \\textbf{x},\\textbf{e}_i \\in \\mathbb{R}^m $$\n",
    "$$ T_{ag} (\\textbf{u},\\textbf{x},\\textbf{e}_i) = \\nabla_{\\textbf{x}} \\textbf{u}_i  $$\n",
    "$$ T_{ag} (\\textbf{u},\\textbf{x},\\textbf{e}_i) = \\nabla_{\\textbf{x}} \\textbf{u}_i  $$\n",
    "$$ T_{ag} (\\textbf{u},\\textbf{x},\\textbf{e}_i+\\textbf{e}_j) = \\nabla_{\\textbf{x}} \\textbf{u}_i + \\nabla_{\\textbf{x}} \\textbf{u}_j $$\n",
    "$$ [T_{ag} (\\textbf{u},\\textbf{x},\\textbf{e}_i)]_{i=1}^n = J_{\\textbf{x}}(\\textbf{u})$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[1.0000, 1.8415, 0.5403, 1.0000]],\n",
      "\n",
      "        [[1.0000, 1.8415, 0.5403, 1.0000]],\n",
      "\n",
      "        [[1.0000, 1.8415, 0.5403, 1.0000]]], grad_fn=<StackBackward0>)\n",
      "[tensor([[[0.5000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.5000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.5000, 0.0000, 0.0000]]], grad_fn=<AddBackward0>), tensor([[[0.5000, 0.5403, 0.0000]],\n",
      "\n",
      "        [[0.5000, 0.5403, 0.0000]],\n",
      "\n",
      "        [[0.5000, 0.5403, 0.0000]]], grad_fn=<AddBackward0>), tensor([[[-0.8415,  0.0000,  0.0000]],\n",
      "\n",
      "        [[-0.8415,  0.0000,  0.0000]],\n",
      "\n",
      "        [[-0.8415,  0.0000,  0.0000]]], grad_fn=<AddBackward0>), tensor([[[0., 2., 0.]],\n",
      "\n",
      "        [[0., 2., 0.]],\n",
      "\n",
      "        [[0., 2., 0.]]], grad_fn=<AddBackward0>)]\n",
      "tensor([[[[ 0.5000,  0.0000,  0.0000],\n",
      "          [ 0.5000,  0.5403,  0.0000],\n",
      "          [-0.8415,  0.0000,  0.0000],\n",
      "          [ 0.0000,  2.0000,  0.0000]]],\n",
      "\n",
      "\n",
      "        [[[ 0.5000,  0.0000,  0.0000],\n",
      "          [ 0.5000,  0.5403,  0.0000],\n",
      "          [-0.8415,  0.0000,  0.0000],\n",
      "          [ 0.0000,  2.0000,  0.0000]]],\n",
      "\n",
      "\n",
      "        [[[ 0.5000,  0.0000,  0.0000],\n",
      "          [ 0.5000,  0.5403,  0.0000],\n",
      "          [-0.8415,  0.0000,  0.0000],\n",
      "          [ 0.0000,  2.0000,  0.0000]]]], grad_fn=<StackBackward0>)\n",
      "torch.Size([3, 1, 4, 3])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 1, 3])"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unit_vectors=torch.eye(4)\n",
    "print(u1)\n",
    "jacobian_rows = [torch.autograd.grad(u1, x1, vec_.unsqueeze(0).unsqueeze(0).tile(u1.shape[0],u1.shape[1],1),\n",
    "            create_graph=True,\n",
    "            retain_graph=True,\n",
    "            allow_unused=True)[0]\n",
    "                     for vec_ in unit_vectors]\n",
    "print(jacobian_rows)\n",
    "print(torch.stack(jacobian_rows,axis=2))\n",
    "print(torch.stack(jacobian_rows,axis=2).shape)\n",
    "\n",
    "torch.autograd.grad(u1, x1, unit_vectors[1].unsqueeze(0).unsqueeze(0).tile(u1.shape[0],u1.shape[1],1),\n",
    "            create_graph=True,\n",
    "            retain_graph=True,\n",
    "            allow_unused=True)[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "\n",
    "def vector_jacobian(u,x):\n",
    "    unit_vectors=torch.eye(u.shape[-1])\n",
    "    jacobian_rows = [torch.autograd.grad(u, x, vec_.unsqueeze(0).unsqueeze(0).tile(u.shape[0],u.shape[1],1),\n",
    "            create_graph=True,\n",
    "            retain_graph=True,\n",
    "            allow_unused=True)[0]\n",
    "                     for vec_ in unit_vectors]\n",
    "    return torch.stack(jacobian_rows,axis=2)\n",
    "\n",
    "\n",
    "def vector_grad(u,x):\n",
    "    unit_vectors=torch.eye(u.shape[-1])\n",
    "    jacobian_rows = [torch.autograd.grad(u, x, vec_.unsqueeze(0).unsqueeze(0).tile(u.shape[0],u.shape[1],1),\n",
    "            create_graph=True,\n",
    "            retain_graph=True,\n",
    "            allow_unused=True)[0]\n",
    "                     for vec_ in unit_vectors]\n",
    "    return torch.diagonal(torch.stack(jacobian_rows,axis=2),dim1=-2,dim2=-1)\n",
    "\n",
    "def x_grad(u,x,i,n):\n",
    "    \"\"\"\n",
    "    gradient of degree wrt x for componen i for u\n",
    "    input:\n",
    "    u and x are tensors with vectors object at dimension -1\n",
    "    [b, n_vectors, vector_dimension]\n",
    "\n",
    "    output:\n",
    "    [b, n_vectors, input_vector_dimension]\n",
    "    \"\"\"\n",
    "    I=torch.eye(u.shape[-1])\n",
    "\n",
    "    u=torch.autograd.grad(u ,x,\n",
    "            I[i].unsqueeze(0).unsqueeze(0).tile(u.shape[0],u.shape[1],1).to(u.device),\n",
    "            create_graph=True,\n",
    "            retain_graph=True,\n",
    "            allow_unused=True)[0]\n",
    "    if n > 1:\n",
    "        for i in range(n-1):\n",
    "            u=vector_grad(u,x)\n",
    "    return u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.5000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.5000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.5000, 0.0000, 0.0000]]], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(x_grad(u1,x1,0,1))\n",
    "udx=x_grad(u1,x1,0,1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 1, 3])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[1., 1., 1.]],\n",
       "\n",
       "        [[1., 1., 1.]],\n",
       "\n",
       "        [[1., 1., 1.]]], requires_grad=True)"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(x1.shape)\n",
    "x1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.5000],\n",
       "        [0.5000],\n",
       "        [0.5000]], grad_fn=<SumBackward1>)"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sum(x1*udx,axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.5000, 0.0000]],\n",
       "\n",
       "        [[0.5000, 0.0000]],\n",
       "\n",
       "        [[0.5000, 0.0000]]], grad_fn=<SliceBackward0>)"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "udx[:,:,:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Residuals debug"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NS reesidual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "def incompresibble_fluid_loss(up,xt,mu=1,rho=1):\n",
    "    l=0\n",
    "    # x-velocity components\n",
    "    l+=x_grad(up,xt,0,1)[...,2] # dudt\n",
    "    l+=torch.sum(up[...,:1]*x_grad(up,xt,0,1)[...,:2],axis=-1) # u * grad u\n",
    "    l+=(mu/rho)*(x_grad(up,xt,2,1)[...,0]) #  dpdx\n",
    "    l-=(mu/rho)*torch.sum(x_grad(up,xt,0,2)[...,:2],axis=-1) # grad**2 u\n",
    "    # y-velocity components\n",
    "    l+=x_grad(up,xt,1,1)[...,2] # dvdt\n",
    "    l+=torch.sum(up[...,1:2]*x_grad(up,xt,0,1)[...,:2],axis=-1) # v * grad v\n",
    "    l+=(mu/rho)*(x_grad(up,xt,2,1)[...,1]) #  dpdy\n",
    "    l-=(mu/rho)*torch.sum(x_grad(up,xt,1,2)[...,:2],axis=-1) # grad**2 v\n",
    "    return l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-1.5316, -0.0218,  1.3527]],\n",
      "\n",
      "        [[ 2.0246,  0.5625, -0.8633]],\n",
      "\n",
      "        [[ 0.5488, -0.9313,  0.3730]]], requires_grad=True)\n",
      "torch.Size([3, 1, 3])\n",
      "torch.Size([3, 1, 3])\n"
     ]
    }
   ],
   "source": [
    "x1 = torch.randn((3,1,3)).requires_grad_(True)  #\n",
    "print(x1)\n",
    "print(x1.shape)\n",
    "\n",
    "u1 = torch.stack([\n",
    "    x1[:,:,0]**0.5,\n",
    "    torch.sin(x1[:,:,1])+x1[:,:,0]**0.5,\n",
    "    torch.cos(x1[:,:,0]),\n",
    "    ],axis=2)\n",
    "\n",
    "print(u1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[   nan],\n",
       "        [0.9955],\n",
       "        [0.3642]], grad_fn=<SubBackward0>)"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "incompresibble_fluid_loss(u1,x1,1,1)-0\n",
    "#x_grad(u1,x1,0,1)[...,0]\n",
    "#print(x1[:,:,:1])\n",
    "#print(x_grad(u1,x1,0,1)[...,:2])\n",
    "#x_grad(u1,x1,0,1)[...,2]\n",
    "#x_grad(u1,x1,0,2)[...,:2]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
