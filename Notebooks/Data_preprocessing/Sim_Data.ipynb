{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "30d21f97-1540-4caa-8f10-d6d57ec6f988",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2D_1P_DF_eq_Dirichlet_Linear_Linear_f_zero_S20x20_T10_1000.csv',\n",
       " '2D_NS_eq_Dirichlet_Linear_Linear_f_zero_10x10.csv',\n",
       " '2D_NS_eq_Dirichlet_Linear_Linear_f_zero_S10x10_T10_500.csv',\n",
       " '2D_poisson_eq_Dirichlet_BC_64x64.csv',\n",
       " '2D_poisson_eq_Dirichlet_Const_f_Const_64x64.csv',\n",
       " '2D_poisson_eq_Dirichlet_Const_Linear_f_Const_64x64.csv',\n",
       " '2D_poisson_eq_Dirichlet_Const_Quad_f_Const_64x64.csv',\n",
       " '2D_poisson_eq_Dirichlet_Exp_Exp_f_Const_64x64.csv',\n",
       " '2D_poisson_eq_Dirichlet_Exp_Exp_f_Linear_Linear_64x64.csv',\n",
       " '2D_poisson_eq_Dirichlet_Linear_Linear_f_Const_64x64.csv',\n",
       " '2D_poisson_eq_Dirichlet_Quad_Quad_f_Const_64x64.csv',\n",
       " '2D_poisson_eq_D_N_R_quad_f_Linear_Linear_64x64.csv',\n",
       " '32x32_2D_poisson_eq_Dirichlet_BC.csv',\n",
       " '32x32_2D_poisson_eq_Dirichlet_BC2.csv',\n",
       " '3D_NS_eq_Dirichlet_Linear_Linear_f_zero_S10x10_T10_500.csv',\n",
       " '3D_poisson_eq_Dirichlet_BC_64x64x64.csv',\n",
       " '3D_poisson_eq_Dirichlet_Const_Linear_f_Const_64x64x64.csv',\n",
       " '60x60_T240_2D_2P_Darcy_flow.csv',\n",
       " '64x64_2D_poisson_eq_Dirichlet_BC.csv',\n",
       " '64x64_2D_poisson_eq_Dirichlet_BC2.csv',\n",
       " '64x64_2D_poisson_eq_Dirichlet_BC3.csv',\n",
       " '64x64_2D_poisson_eq_Dirichlet_BC4.csv',\n",
       " '64x64_2D_poisson_eq_Dirichlet_BC5.csv',\n",
       " '64x64_2D_poisson_eq_Dirichlet_BC6.csv',\n",
       " '64x64_2D_poisson_eq_Dirichlet_BC_V_BC_H.csv',\n",
       " '64x64_2D_poisson_eq_Dirichlet_DBC_V_NBC_H.csv',\n",
       " 'PERMI_0_all.h5',\n",
       " 'PERMI_1000_all.h5',\n",
       " 'PERMI_100_all.h5',\n",
       " 'PERMI_1_all.h5',\n",
       " 'PERMI_3_all.h5']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "ROOT=\"/app/Exploring_repo\"\n",
    "#ROOT=\"/share_zeta/Proxy-Sim/PhysicsSimulationDeepLearning\"\n",
    "os.listdir(os.path.join(ROOT,\"Data\"))\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a4742741",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting h5py\n",
      "  Downloading h5py-3.11.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.5 kB)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.8/dist-packages (from h5py) (1.24.1)\n",
      "Downloading h5py-3.11.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.3/5.3 MB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0mm\n",
      "\u001b[?25hInstalling collected packages: h5py\n",
      "Successfully installed h5py-3.11.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "! pip install h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fd0bd974",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keys: <KeysViewHDF5 ['BHP', 'Restrictions', 'features', 'outout']>\n",
      "<class 'h5py._hl.group.Group'>\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import h5py\n",
    "filename = os.path.join(ROOT,\"Data\",\"PERMI_0_all.h5\")\n",
    "\n",
    "with h5py.File(filename, \"r\") as f:\n",
    "    # Print all root level object names (aka keys) \n",
    "    # these can be group or dataset names \n",
    "    print(\"Keys: %s\" % f.keys())\n",
    "    # get first object name/key; may or may NOT be a group\n",
    "    a_group_key = list(f.keys())[0]\n",
    "\n",
    "    # get the object type for a_group_key: usually group or dataset\n",
    "    print(type(f[a_group_key]))\n",
    "    d1=pd.DataFrame(f[a_group_key])\n",
    "\n",
    "    data = list(f[a_group_key])\n",
    "\n",
    "    # If a_group_key is a dataset name, \n",
    "    # this gets the dataset values and returns as a list\n",
    "    data = list(f[a_group_key])\n",
    "    # preferred methods to get dataset values:\n",
    "    ds_obj = f[a_group_key]      # returns as a h5py dataset object\n",
    "    #ds_arr = f[a_group_key][()]  # returns as a numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f9d0031b",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = h5py.File(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f7c8cd42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BHP\n",
      "<class 'h5py._hl.group.Group'>\n",
      "Restrictions\n",
      "<class 'h5py._hl.group.Group'>\n",
      "features\n",
      "<class 'h5py._hl.group.Group'>\n",
      "outout\n",
      "<class 'h5py._hl.group.Group'>\n",
      "axis0\n",
      "axis1\n",
      "block0_items\n",
      "block0_values\n",
      "block1_items\n",
      "block1_values\n",
      "(720,)\n",
      "(8, 720)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['QG', 'QO', 'QW'], dtype='<U2')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = h5py.File(filename)\n",
    "get_prop = lambda com_prop: com_prop.split(\"_\")[0]\n",
    "\n",
    "for key in f.keys():\n",
    "    print(key) #Names of the root level object names in HDF5 file - can be groups or datasets.\n",
    "    print(type(f[key]))\n",
    "\n",
    "group = f[\"features\"]\n",
    "#group = f[\"outout\"]\n",
    "\n",
    "#Checkout what keys are inside that group.\n",
    "for key in group.keys():\n",
    "    print(key)\n",
    "\n",
    "# This assumes group[some_key_inside_the_group] is a dataset, \n",
    "# and returns a np.array:\n",
    "item = group[\"block0_items\"][()]\n",
    "data = group[\"block0_values\"][()]\n",
    "#Do whatever you want with data\n",
    "\n",
    "#After you are done\n",
    "#f.close()\n",
    "print(item.shape)\n",
    "print(data.shape)\n",
    "cols_list=list(map(lambda c: c.decode(\"utf-8\"),item.tolist()))\n",
    "pd.DataFrame(\n",
    "    data=data,\n",
    "    columns=cols_list\n",
    "    )\n",
    "\n",
    "\n",
    "np.unique(np.array(list(map(get_prop,cols_list[:]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2adab62b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1999.96 ,  838.159,  784.852, ...,  462.593,  458.564,  454.62 ],\n",
       "       [1999.97 , 1105.55 , 1102.56 , ...,  374.497,  371.75 ,  369.02 ],\n",
       "       [1999.96 ,  933.916,  943.075, ...,  375.417,  372.656,  369.895],\n",
       "       ...,\n",
       "       [1999.96 ,  871.036,  870.662, ...,  199.658,  198.566,  197.487],\n",
       "       [   0.   ,    0.   ,    0.   , ...,    0.   ,    0.   ,    0.   ],\n",
       "       [   0.   ,    0.   ,    0.   , ...,    0.   ,    0.   ,    0.   ]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0ddb7dc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['QG_1', 'QO_1', 'QW_1']\n",
      "(8, 3, 240)\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"None of [Index(['GridCentroidX', 'GridCentroidY', 'Z', 'PermeabilityI', 'PermeabilityJ',\\n       'PermeabilityK'],\\n      dtype='object')] are in the [columns]\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[26], line 13\u001b[0m\n\u001b[1;32m     11\u001b[0m SVP\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mstack(\u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mmap\u001b[39m(\u001b[38;5;28;01mlambda\u001b[39;00m t: features_data[\u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mmap\u001b[39m(\u001b[38;5;28;01mlambda\u001b[39;00m p: p\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;28mstr\u001b[39m(t),props))]\u001b[38;5;241m.\u001b[39mvalues,np\u001b[38;5;241m.\u001b[39marange(\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m241\u001b[39m))),axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28mprint\u001b[39m(SVP\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m---> 13\u001b[0m XYKIJ\u001b[38;5;241m=\u001b[39m\u001b[43mfeatures_data\u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mGridCentroidX\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mGridCentroidY\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mZ\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mPermeabilityI\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mPermeabilityJ\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mPermeabilityK\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mvalues\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/core/frame.py:3767\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3765\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n\u001b[1;32m   3766\u001b[0m         key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[0;32m-> 3767\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_indexer_strict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcolumns\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m   3769\u001b[0m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[1;32m   3770\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/core/indexes/base.py:5877\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[0;34m(self, key, axis_name)\u001b[0m\n\u001b[1;32m   5874\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   5875\u001b[0m     keyarr, indexer, new_indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[0;32m-> 5877\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raise_if_missing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeyarr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   5879\u001b[0m keyarr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtake(indexer)\n\u001b[1;32m   5880\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[1;32m   5881\u001b[0m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/core/indexes/base.py:5938\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[0;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[1;32m   5936\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m use_interval_msg:\n\u001b[1;32m   5937\u001b[0m         key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[0;32m-> 5938\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   5940\u001b[0m not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]]\u001b[38;5;241m.\u001b[39munique())\n\u001b[1;32m   5941\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not in index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mKeyError\u001b[0m: \"None of [Index(['GridCentroidX', 'GridCentroidY', 'Z', 'PermeabilityI', 'PermeabilityJ',\\n       'PermeabilityK'],\\n      dtype='object')] are in the [columns]\""
     ]
    }
   ],
   "source": [
    "\n",
    "cols_list=list(map(lambda c: c.decode(\"utf-8\"),item.tolist()))\n",
    "props=np.unique(np.array(list(map(get_prop,cols_list[18:]))))\n",
    "t=1\n",
    "print(list(map(lambda p: p+\"_\"+str(t),props)))\n",
    "\n",
    "features_data=pd.DataFrame(\n",
    "    data=data,\n",
    "    columns=cols_list\n",
    "    )\n",
    "\n",
    "SVP=np.stack(list(map(lambda t: features_data[list(map(lambda p: p+\"_\"+str(t),props))].values,np.arange(1,241))),axis=2)\n",
    "print(SVP.shape)\n",
    "XYKIJ=features_data[[\"GridCentroidX\",\"GridCentroidY\",\"Z\",\"PermeabilityI\",\"PermeabilityJ\",\"PermeabilityK\"]].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "370226d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02b7a46f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from einops import repeat,rearrange\n",
    "#['OS_1', 'OV_1', 'OVF_1', 'P_1', 'SGR_1', 'WS_1', 'WV_1']\n",
    "def solution_data_normalization(Uv,X):\n",
    "#    Uv_=np.concatenate([Vv_,Pv_],axis=-1)\n",
    "    X=repeat(X[:,:],\"p v -> t p v\",t=240)\n",
    "    T=repeat(np.array([t for t in range(1,241)]),\"t -> t p 1\",p=X.shape[1])\n",
    "    XT=np.concatenate([X,T],axis=-1)\n",
    "    Uv=rearrange(Uv,\"p v t-> (t p) v\")\n",
    "    XT=rearrange(XT,\"t p v -> (t p) v\")\n",
    "\n",
    "    data_dict={\n",
    "        \"Os\":Uv[:,0].tolist(),\n",
    "        \"Bo\":Uv[:,2].tolist(),\n",
    "        \"Ws\":Uv[:,5].tolist(),\n",
    "        \"P\":Uv[:,3].tolist(),\n",
    "        \"x\":XT[:,0].tolist(),\n",
    "        \"y\":XT[:,1].tolist(),\n",
    "        \"z\":XT[:,2].tolist(),\n",
    "        \"Ki\":XT[:,3].tolist(),\n",
    "        \"Kj\":XT[:,4].tolist(),\n",
    "        \"Kk\":XT[:,5].tolist(),\n",
    "        \"t\":XT[:,6].tolist()\n",
    "    }\n",
    "    return pd.DataFrame(data_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cda3a2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=solution_data_normalization(SVP,XYKIJ)\n",
    "data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
