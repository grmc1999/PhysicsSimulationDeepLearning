{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/guillermo.carrilho/PhysicsSimulationDeepLearning\n"
     ]
    }
   ],
   "source": [
    "! pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4865e9b0-c759-451f-a019-96d5da1ef942",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "\n",
    "ROOT=\"/home/guillermo.carrilho/PhysicsSimulationDeepLearning\"\n",
    "\n",
    "sys.path.append(os.path.join(ROOT,\"Physical_models\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(xˢ=64, yˢ=64), bounds=Box(x=(0, 1), y=(0, 1))"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#mesh = geom.build_mesh(Box(x=1, y=1), x=100, y=100)\n",
    "#CenteredGrid(0, 0, x=32, y=32, bounds=Box(x=1, y=1)).geometry\n",
    "\n",
    "#resolution = math.linspace(0, 1, spatial(y=31))\n",
    "#Box(resolution)\n",
    "#Box?\n",
    "UniformGrid(x=64, y=64,bounds=Box(x=1, y=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 575,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from Differentiable_simulation import two_phase_flow,dK_w,K_w,K_o\n",
    "from phi.torch.flow import *\n",
    "\n",
    "\n",
    "geo_w=UniformGrid(x=64, y=64,bounds=Box(x=5e3, y=5e3))\n",
    "phi_w=Field( geo_w,values=tensor(0.0),\n",
    "      boundary= {\n",
    "          'x-':3e3,\n",
    "          'x+': ZERO_GRADIENT,\n",
    "          'y-': ZERO_GRADIENT,\n",
    "          'y+': ZERO_GRADIENT\n",
    " })\n",
    "\n",
    "geo_o=UniformGrid(x=64, y=64,bounds=Box(x=5e3, y=5e3))\n",
    "phi_o=Field( geo_o,values=tensor(0.0),\n",
    "      boundary= {\n",
    "          'x-': ZERO_GRADIENT,\n",
    "          'x+': ZERO_GRADIENT,\n",
    "          'y-': ZERO_GRADIENT,\n",
    "          'y+': ZERO_GRADIENT\n",
    " })\n",
    "\n",
    "phy=two_phase_flow(\n",
    "    phi_w,\n",
    "    phi_o,\n",
    "    dt=0.01,\n",
    "    w_advection_solver=lambda v: Solve('CG-adaptive',1e-4,1e-4,x0=v),\n",
    "    o_advection_solver=lambda v: Solve('CG-adaptive',1e-4,1e-4,x0=v)\n",
    "    #advection_solver=lambda v: Solve('CG-adaptive',1e-3,1e-3,x0=v)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 574,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Differentiable_simulation import K_w_f_t,K_o_f_t,dsdpc,dsK_w_f_t,dsK_o_f_t,grad_phi_dK\n",
    "SWR=0.3\n",
    "SOR=0.1\n",
    "KRW=0.05\n",
    "KRO=0.7\n",
    "NW=2.0\n",
    "NO=3.5\n",
    "MUW=1.0\n",
    "MUO=1.0\n",
    "PD=2*(1e3) # Pa\n",
    "LAMBDA=1\n",
    "\n",
    "#S_w=(lambda p_c:math.clip(SWR+(1-SWR)*(p_c/PD)**(-1*LAMBDA),1.0,0.0)) # add conditions for p_c=0\n",
    "\n",
    "#dsdpc=(lambda p_c:(((SWR-1)*LAMBDA)/PD)*((math.clip(p_c,PD))/(PD))**(-1*(LAMBDA + 1)))\n",
    "\n",
    "dsdpc=(lambda p_c:math.clip((-1*LAMBDA)*((S_w(p_c)-SWR)/PD),lower_limit=1e-6))\n",
    "\n",
    "S_w=(lambda p_c:math.clip(SWR+(1-SWR)*(p_c/PD)**(-1*LAMBDA),SWR,(1-SOR))) # add conditions for p_c=0\n",
    "#S_w=(lambda p_c:SWR+(1-SWR)*(math.clip(p_c,PD)/PD)**(-1*LAMBDA)) # add conditions for p_c=0\n",
    "\n",
    "K_w=lambda p_c:stack(\n",
    "    [stack([K_w_f_t(S_w(p_c))/(MUW*dsdpc(p_c)),math.zeros_like(p_c)],batch(\"k\") ),\n",
    "    stack([math.zeros_like(p_c),K_w_f_t(S_w(p_c))/(MUW*dsdpc(p_c))],batch(\"k\") )],batch(\"KK\"))\n",
    "\n",
    "K_o=lambda p_c:stack(\n",
    "    [stack([K_o_f_t(S_w(p_c))/(MUW*dsdpc(p_c)),math.zeros_like(p_c)],batch(\"k\") ),\n",
    "    stack([math.zeros_like(p_c),K_o_f_t(S_w(p_c))/(MUW*dsdpc(p_c))],batch(\"k\") )],batch(\"KK\"))\n",
    "\n",
    "dK_w=lambda p_c:stack(\n",
    "    [stack([dsdpc(p_c)*dsK_w_f_t(S_w(p_c))/(MUW*dsdpc(p_c)),math.zeros_like(p_c)],batch(\"dk\") ),\n",
    "    stack([math.zeros_like(p_c),dsdpc(p_c)*dsK_w_f_t(S_w(p_c))/(MUW*dsdpc(p_c))],batch(\"dk\") )],batch(\"dKK\"))\n",
    "\n",
    "dK_o=lambda p_c:stack(\n",
    "    [stack([dsdpc(p_c)*dsK_o_f_t(S_w(p_c))/(MUW*dsdpc(p_c)),math.zeros_like(p_c)],batch(\"dk\") ),\n",
    "    stack([math.zeros_like(p_c),dsdpc(p_c)*dsK_o_f_t(S_w(p_c))/(MUW*dsdpc(p_c))],batch(\"dk\") )],batch(\"dKK\"))\n",
    "\n",
    "\n",
    "class two_phase_flow(object):\n",
    "  def __init__(self,phi_w,phi_o,dt,w_advection_solver,o_advection_solver):\n",
    "    #self.v0=v0\n",
    "    self.phi_w=phi_w\n",
    "    self.phi_o=phi_o\n",
    "    self.dt=dt\n",
    "    self.p=None\n",
    "    self.w_advection_solver=w_advection_solver\n",
    "    self.o_advection_solver=o_advection_solver\n",
    "\n",
    "\n",
    "  def compute_p_c(self,phi_w,phi_o):\n",
    "    p_c=phi_w.sample(phi_w.geometry) -\\\n",
    "    phi_o.sample(phi_o.geometry)\n",
    "    return p_c\n",
    "\n",
    "  def compute_convective_velocity(self,phi_a,phi_b,dK_a):\n",
    "    p_c=self.compute_p_c(self.phi_w,self.phi_o)\n",
    "    convective_velocity = grad_phi_dK(phi_a,dK_a(p_c))\\\n",
    "                         - grad_phi_dK(phi_b,dK_a(p_c))\n",
    "\n",
    "    V=unstack(convective_velocity,\"dk\")\n",
    "    convective_velocity=Field(self.phi_o.geometry,values=vec(x=V[0],y=V[1]))\n",
    "    return convective_velocity\n",
    "\n",
    "  #def compute_anisotropic_viscosity_effect(self):\n",
    "    # reformulate differential solver\n",
    "    \n",
    "  def phi_w_momentum_eq(self,phi_w,phi_o, dt):\n",
    "    #grad_phi_w=field.spatial_gradient(self.phi_w,self.phi_w.boundary)\n",
    "    p_c=self.compute_p_c(phi_w,phi_o)\n",
    "    w_advection_term = dt * advect.semi_lagrangian((phi_o),\n",
    "                                                    self.compute_convective_velocity(phi_w,phi_o,dK_w),\n",
    "                                                    dt).sample(phi_w.geometry)\n",
    "    o_advection_term = dt * advect.semi_lagrangian((phi_w),\n",
    "                                                    self.compute_convective_velocity(phi_o,phi_w,dK_o),\n",
    "                                                    dt).sample(phi_w.geometry)\n",
    "    w_diffusion_term = dt * anisotropic_diffusion.implicit(phi_w,K_w(p_c), dt=dt,correct_skew=False).sample(phi_w.geometry)\n",
    "    o_diffusion_term = dt * anisotropic_diffusion.implicit(phi_o,K_o(p_c), dt=dt,correct_skew=False).sample(phi_w.geometry)\n",
    "\n",
    "    return phi_w + phi_w.with_values(w_advection_term + o_advection_term) + phi_w.with_values(w_diffusion_term - o_diffusion_term)\n",
    "  \n",
    "  def phi_o_momentum_eq(self,phi_o,phi_w, dt):\n",
    "    #grad_phi_w=field.spatial_gradient(phi_w,phi_w.boundary)\n",
    "    p_c=self.compute_p_c(phi_w,phi_o)\n",
    "    w_advection_term = dt * advect.semi_lagrangian((phi_o),\n",
    "                                                    self.compute_convective_velocity(phi_o,phi_w,dK_w),\n",
    "                                                    dt).sample(phi_o.geometry)\n",
    "    o_advection_term = dt * advect.semi_lagrangian((phi_w),\n",
    "                                                    self.compute_convective_velocity(phi_w,phi_o,dK_o),\n",
    "                                                    dt).sample(phi_o.geometry)\n",
    "    w_diffusion_term = dt * anisotropic_diffusion.implicit(phi_w,K_w(p_c), dt=dt,correct_skew=False).sample(phi_o.geometry)\n",
    "    o_diffusion_term = dt * anisotropic_diffusion.implicit(phi_o,K_o(p_c), dt=dt,correct_skew=False).sample(phi_o.geometry)\n",
    "\n",
    "    return phi_o + phi_o.with_values(w_advection_term + o_advection_term) + phi_o.with_values(o_diffusion_term - w_diffusion_term)\n",
    "\n",
    "\n",
    "  def implicit_time_step(self, phi_w,phi_o, dt):\n",
    "    new_phi_w = math.solve_linear(self.phi_w_momentum_eq, phi_w, self.w_advection_solver(phi_w),phi_o, dt=-dt)\n",
    "    new_phi_o = math.solve_linear(self.phi_o_momentum_eq, phi_o, self.o_advection_solver(phi_o),phi_w, dt=-dt)\n",
    "    return new_phi_w,new_phi_o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 576,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m(xˢ=64, yˢ=64)\u001b[0m \u001b[94mconst 0.8999999761581421\u001b[0m\n",
      "\u001b[92m(xˢ=64, yˢ=64)\u001b[0m \u001b[94mconst 9.999999974752427e-07\u001b[0m\n",
      "\u001b[92m(xˢ=64, yˢ=64)\u001b[0m \u001b[94mconst 0.0\u001b[0m\n",
      "\u001b[92m(dKKᵇ=2, dkᵇ=2, xˢ=64, yˢ=64)\u001b[0m \u001b[94m0.245 ± 0.245\u001b[0m \u001b[37m(0e+00...5e-01)\u001b[0m\n",
      "\u001b[92m(KKᵇ=2, kᵇ=2, xˢ=64, yˢ=64)\u001b[0m \u001b[94m7.35e+04 ± 7.3e+04\u001b[0m \u001b[37m(0e+00...1e+05)\u001b[0m\n",
      "\u001b[92m(xˢ=64, yˢ=64, vectorᶜ=x,y)\u001b[0m \u001b[94m-0.073 ± 0.828\u001b[0m \u001b[37m(-9e+00...0e+00)\u001b[0m\n",
      "\u001b[92m(KKᵇ=2, kᵇ=2, xˢ=64, yˢ=64)\u001b[0m \u001b[94mconst 0.0 / nan\u001b[0m\n",
      "\u001b[92m(dKKᵇ=2, dkᵇ=2, xˢ=64, yˢ=64)\u001b[0m \u001b[94mconst 0.0 / nan\u001b[0m\n",
      "\u001b[92m(xˢ=64, yˢ=64, vectorᶜ=x,y)\u001b[0m \u001b[94mnan ± nan\u001b[0m \u001b[37m(nan...nan)\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "#from Differentiable_simulation import K_o_f_t,S_w,dK_o,dK_w,dK_o,dsdpc\n",
    "import anisotropic_diffusion\n",
    "print(S_w(phy.compute_p_c(phi_w,phi_o)))\n",
    "print(dsdpc(phy.compute_p_c(phi_w,phi_o)))\n",
    "print(phy.compute_p_c(phi_w,phi_o))\n",
    "print(dK_w(phy.compute_p_c(phi_w,phi_o)))\n",
    "print(K_w(phy.compute_p_c(phi_w,phi_o)))\n",
    "print(phy.compute_convective_velocity(phi_w,phi_o,dK_w).sample(phi_w.geometry))\n",
    "print(K_o(phy.compute_p_c(phi_w,phi_o)))\n",
    "print(dK_o(phy.compute_p_c(phi_w,phi_o)))\n",
    "print(phy.compute_convective_velocity(phi_w,phi_o,dK_o).sample(phi_o.geometry))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 577,
   "metadata": {},
   "outputs": [],
   "source": [
    "phi=(phi_w,phi_o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 581,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotConverged",
     "evalue": "Φ-ML CG (PyTorch*) did not converge to rel_tol=1e-05, abs_tol=1e-05 within 1000 iterations. Max residual: nan",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotConverged\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[581], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m----> 2\u001b[0m     phi\u001b[38;5;241m=\u001b[39m\u001b[43mphy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimplicit_time_step\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mphi\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m1e-5\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[574], line 97\u001b[0m, in \u001b[0;36mtwo_phase_flow.implicit_time_step\u001b[0;34m(self, phi_w, phi_o, dt)\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mimplicit_time_step\u001b[39m(\u001b[38;5;28mself\u001b[39m, phi_w,phi_o, dt):\n\u001b[0;32m---> 97\u001b[0m   new_phi_w \u001b[38;5;241m=\u001b[39m \u001b[43mmath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msolve_linear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mphi_w_momentum_eq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mphi_w\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mw_advection_solver\u001b[49m\u001b[43m(\u001b[49m\u001b[43mphi_w\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43mphi_o\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43mdt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     98\u001b[0m   new_phi_o \u001b[38;5;241m=\u001b[39m math\u001b[38;5;241m.\u001b[39msolve_linear(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mphi_o_momentum_eq, phi_o, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mo_advection_solver(phi_o),phi_w, dt\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39mdt)\n\u001b[1;32m     99\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m new_phi_w,new_phi_o\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/phiml/math/_optimize.py:701\u001b[0m, in \u001b[0;36msolve_linear\u001b[0;34m(f, y, solve, grad_for_f, f_kwargs, *f_args, **f_kwargs_)\u001b[0m\n\u001b[1;32m    698\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result  \u001b[38;5;66;03m# must return exactly `x` so gradient isn't computed w.r.t. other quantities\u001b[39;00m\n\u001b[1;32m    700\u001b[0m _function_solve \u001b[38;5;241m=\u001b[39m attach_gradient_solve(_function_solve_forward, auxiliary_args\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mis_backprop,f_kwargs,solve\u001b[39m\u001b[38;5;124m'\u001b[39m, matrix_adjoint\u001b[38;5;241m=\u001b[39mgrad_for_f)\n\u001b[0;32m--> 701\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_function_solve\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msolve\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mf_kwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/phiml/math/_functional.py:963\u001b[0m, in \u001b[0;36mCustomGradientFunction.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    958\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraces) \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m8\u001b[39m:\n\u001b[1;32m    959\u001b[0m                 warnings\u001b[38;5;241m.\u001b[39mwarn(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m has been traced \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraces)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m times.\u001b[39m\n\u001b[1;32m    960\u001b[0m \u001b[38;5;124mTo avoid memory leaks, call \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mf_name(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.traces.clear(), \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mf_name(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.recorded_mappings.clear().\u001b[39m\n\u001b[1;32m    961\u001b[0m \u001b[38;5;124mTraces can be avoided by jit-compiling the code that calls custom gradient functions.\u001b[39m\n\u001b[1;32m    962\u001b[0m \u001b[38;5;124m\"\"\"\u001b[39m, \u001b[38;5;167;01mRuntimeWarning\u001b[39;00m, stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m--> 963\u001b[0m         native_result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraces\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mnatives\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# With PyTorch + jit, this does not call forward_native every time\u001b[39;00m\n\u001b[1;32m    964\u001b[0m         output_key \u001b[38;5;241m=\u001b[39m match_output_signature(key, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrecorded_mappings, \u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m    965\u001b[0m         output_tensors \u001b[38;5;241m=\u001b[39m assemble_tensors(native_result, output_key\u001b[38;5;241m.\u001b[39mspecs)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/phiml/backend/torch/_torch_backend.py:251\u001b[0m, in \u001b[0;36mTorchBackend.custom_gradient.<locals>.select_jit\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m    249\u001b[0m args \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mas_tensor(arg) \u001b[38;5;28;01mfor\u001b[39;00m arg \u001b[38;5;129;01min\u001b[39;00m args]\n\u001b[1;32m    250\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m CURRENT_JIT_CALLS:\n\u001b[0;32m--> 251\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    252\u001b[0m jit \u001b[38;5;241m=\u001b[39m CURRENT_JIT_CALLS[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m    253\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_get_tracing_state() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:  \u001b[38;5;66;03m# first call: record this function\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/function.py:575\u001b[0m, in \u001b[0;36mFunction.apply\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m    572\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_are_functorch_transforms_active():\n\u001b[1;32m    573\u001b[0m     \u001b[38;5;66;03m# See NOTE: [functorch vjp and autograd interaction]\u001b[39;00m\n\u001b[1;32m    574\u001b[0m     args \u001b[38;5;241m=\u001b[39m _functorch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39munwrap_dead_wrappers(args)\n\u001b[0;32m--> 575\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m    577\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_setup_ctx_defined:\n\u001b[1;32m    578\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    579\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIn order to use an autograd.Function with functorch transforms \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    580\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(vmap, grad, jvp, jacrev, ...), it must override the setup_context \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    581\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstaticmethod. For more details, please see \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    582\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://pytorch.org/docs/main/notes/extending.func.html\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    583\u001b[0m     )\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/phiml/backend/torch/_torch_backend.py:1206\u001b[0m, in \u001b[0;36mconstruct_torch_custom_function.<locals>.TorchCustomFunction.forward\u001b[0;34m(ctx, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1204\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m f_example_output\n\u001b[1;32m   1205\u001b[0m ML_LOGGER\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTorchScript -> run compiled \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mf\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m with args \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m[(\u001b[38;5;28mtuple\u001b[39m(a\u001b[38;5;241m.\u001b[39mshape),\u001b[38;5;250m \u001b[39ma\u001b[38;5;241m.\u001b[39mrequires_grad)\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mfor\u001b[39;00m\u001b[38;5;250m \u001b[39ma\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01min\u001b[39;00m\u001b[38;5;250m \u001b[39margs]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 1206\u001b[0m y \u001b[38;5;241m=\u001b[39m \u001b[43m(\u001b[49m\u001b[43mjit_f\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1207\u001b[0m ctx\u001b[38;5;241m.\u001b[39msave_for_backward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39my)\n\u001b[1;32m   1208\u001b[0m ctx\u001b[38;5;241m.\u001b[39minput_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(args)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/phiml/math/_functional.py:919\u001b[0m, in \u001b[0;36mCustomGradientFunction._trace.<locals>.forward_native\u001b[0;34m(*natives)\u001b[0m\n\u001b[1;32m    917\u001b[0m kwargs \u001b[38;5;241m=\u001b[39m assemble_tree(in_key\u001b[38;5;241m.\u001b[39mtree, in_tensors, attr_type\u001b[38;5;241m=\u001b[39mvariable_attributes)\n\u001b[1;32m    918\u001b[0m ML_LOGGER\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRunning forward pass of custom op \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mforward_native\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m given args \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtuple\u001b[39m(kwargs\u001b[38;5;241m.\u001b[39mkeys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m containing \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(natives)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m native tensors\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 919\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43min_key\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mauxiliary_kwargs\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Tensor or tuple/list of Tensors\u001b[39;00m\n\u001b[1;32m    920\u001b[0m nest, out_tensors \u001b[38;5;241m=\u001b[39m disassemble_tree(result, cache\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, attr_type\u001b[38;5;241m=\u001b[39mvariable_attributes)\n\u001b[1;32m    921\u001b[0m result_natives, result_shapes, specs \u001b[38;5;241m=\u001b[39m disassemble_tensors(out_tensors, expand\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/phiml/math/_optimize.py:697\u001b[0m, in \u001b[0;36msolve_linear.<locals>._function_solve_forward\u001b[0;34m(y, solve, f_args, f_kwargs, is_backprop)\u001b[0m\n\u001b[1;32m    694\u001b[0m         y_native \u001b[38;5;241m=\u001b[39m y_native[batch_index]\n\u001b[1;32m    695\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m y_native\n\u001b[0;32m--> 697\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43m_linear_solve_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msolve\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnative_lin_f\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpattern_dims_in\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnon_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx0_tensor\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnames\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpattern_dims_out\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnon_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_tensor\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnames\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreconditioner\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbackend\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbackend\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_backprop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_backprop\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    698\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/phiml/math/_optimize.py:753\u001b[0m, in \u001b[0;36m_linear_solve_forward\u001b[0;34m(y, solve, native_lin_op, pattern_dims_in, pattern_dims_out, preconditioner, backend, is_backprop)\u001b[0m\n\u001b[1;32m    751\u001b[0m     method \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mscipy-\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m method\n\u001b[1;32m    752\u001b[0m t \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mperf_counter()\n\u001b[0;32m--> 753\u001b[0m ret \u001b[38;5;241m=\u001b[39m \u001b[43mbackend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear_solve\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnative_lin_op\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_native\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx0_native\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrtol\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43matol\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_iter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreconditioner\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmatrix_offset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    754\u001b[0m t \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mperf_counter() \u001b[38;5;241m-\u001b[39m t\n\u001b[1;32m    755\u001b[0m trj_dims \u001b[38;5;241m=\u001b[39m [batch(trajectory\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(max_iter))] \u001b[38;5;28;01mif\u001b[39;00m trj \u001b[38;5;28;01melse\u001b[39;00m []\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/phiml/backend/_backend.py:1483\u001b[0m, in \u001b[0;36mBackend.linear_solve\u001b[0;34m(self, method, lin, y, x0, rtol, atol, max_iter, pre, matrix_offset)\u001b[0m\n\u001b[1;32m   1481\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconjugate_gradient(lin, y, x0, rtol, atol, max_iter, pre, matrix_offset)\n\u001b[1;32m   1482\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m method \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCG-adaptive\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m-> 1483\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconjugate_gradient_adaptive\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlin\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrtol\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43matol\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_iter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpre\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmatrix_offset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1484\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m method \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbiCG\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbiCG-stab(0)\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n\u001b[1;32m   1485\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbi_conjugate_gradient(lin, y, x0, rtol, atol, max_iter, pre, matrix_offset, poly_order\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/phiml/backend/torch/_torch_backend.py:916\u001b[0m, in \u001b[0;36mTorchBackend.conjugate_gradient_adaptive\u001b[0;34m(self, lin, y, x0, rtol, atol, max_iter, pre, matrix_offset)\u001b[0m\n\u001b[1;32m    914\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_available(y):\n\u001b[1;32m    915\u001b[0m         warnings\u001b[38;5;241m.\u001b[39mwarn(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCG with preconditioners is not optimized for PyTorch and will always run the maximum number of iterations when JIT-compiled (max_iter=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmax_iter\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m).\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;167;01mRuntimeWarning\u001b[39;00m)\n\u001b[0;32m--> 916\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mBackend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconjugate_gradient_adaptive\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlin\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrtol\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43matol\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_iter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpre\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmatrix_offset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    917\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(lin, torch\u001b[38;5;241m.\u001b[39mTensor), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBatched matrices are not yet supported\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    918\u001b[0m batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstaticshape(y)[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/phiml/backend/_backend.py:1502\u001b[0m, in \u001b[0;36mBackend.conjugate_gradient_adaptive\u001b[0;34m(self, lin, y, x0, rtol, atol, max_iter, pre, matrix_offset)\u001b[0m\n\u001b[1;32m   1500\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\" Conjugate gradient algorithm with adaptive step size. Signature matches to `Backend.linear_solve()`. \"\"\"\u001b[39;00m\n\u001b[1;32m   1501\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_linalg\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m cg_adaptive\n\u001b[0;32m-> 1502\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcg_adaptive\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlin\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrtol\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43matol\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_iter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpre\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmatrix_offset\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/phiml/backend/_linalg.py:104\u001b[0m, in \u001b[0;36mcg_adaptive\u001b[0;34m(b, lin, y, x0, rtol, atol, max_iter, pre, matrix_offset)\u001b[0m\n\u001b[1;32m    102\u001b[0m batch_size \u001b[38;5;241m=\u001b[39m b\u001b[38;5;241m.\u001b[39mstaticshape(y)[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    103\u001b[0m x \u001b[38;5;241m=\u001b[39m x0\n\u001b[0;32m--> 104\u001b[0m dx \u001b[38;5;241m=\u001b[39m residual \u001b[38;5;241m=\u001b[39m y \u001b[38;5;241m-\u001b[39m \u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlin\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmatrix_offset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    105\u001b[0m dy \u001b[38;5;241m=\u001b[39m linear(b, lin, dx, matrix_offset)\n\u001b[1;32m    106\u001b[0m iterations \u001b[38;5;241m=\u001b[39m b\u001b[38;5;241m.\u001b[39mzeros([batch_size], INT32)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/phiml/backend/_linalg.py:831\u001b[0m, in \u001b[0;36mlinear\u001b[0;34m(b, lin, vector, matrix_offset, get_without_offset)\u001b[0m\n\u001b[1;32m    829\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mlinear\u001b[39m(b: Backend, lin, vector, matrix_offset, get_without_offset\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m    830\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Apply linear function with matrix offset to vector, i.e. `(lin+matrix_offset) @ vector`\"\"\"\u001b[39;00m\n\u001b[0;32m--> 831\u001b[0m     result \u001b[38;5;241m=\u001b[39m result_wo_offset \u001b[38;5;241m=\u001b[39m \u001b[43mb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlin\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvector\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    832\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m matrix_offset \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    833\u001b[0m         result \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m b\u001b[38;5;241m.\u001b[39msum(vector, \u001b[38;5;241m1\u001b[39m, keepdims\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;241m*\u001b[39m matrix_offset[:, \u001b[38;5;28;01mNone\u001b[39;00m]\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/phiml/backend/_backend.py:1511\u001b[0m, in \u001b[0;36mBackend.linear\u001b[0;34m(self, lin, vector)\u001b[0m\n\u001b[1;32m   1509\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mlinear\u001b[39m(\u001b[38;5;28mself\u001b[39m, lin, vector):\n\u001b[1;32m   1510\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(lin):\n\u001b[0;32m-> 1511\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvector\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1512\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(lin, (\u001b[38;5;28mtuple\u001b[39m, \u001b[38;5;28mlist\u001b[39m)):\n\u001b[1;32m   1513\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m lin_i \u001b[38;5;129;01min\u001b[39;00m lin:\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/phiml/math/_optimize.py:689\u001b[0m, in \u001b[0;36msolve_linear.<locals>._function_solve_forward.<locals>.native_lin_f\u001b[0;34m(native_x, batch_index)\u001b[0m\n\u001b[1;32m    687\u001b[0m     native_x \u001b[38;5;241m=\u001b[39m backend\u001b[38;5;241m.\u001b[39mtile(backend\u001b[38;5;241m.\u001b[39mexpand_dims(native_x), [batches\u001b[38;5;241m.\u001b[39mvolume, \u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m    688\u001b[0m x \u001b[38;5;241m=\u001b[39m assemble_tree(x0_nest, [reshaped_tensor(native_x, [batches, non_batch(x0_tensor)] \u001b[38;5;28;01mif\u001b[39;00m backend\u001b[38;5;241m.\u001b[39mndims(native_x) \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m [non_batch(x0_tensor)], convert\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)], attr_type\u001b[38;5;241m=\u001b[39mvariable_attributes)\n\u001b[0;32m--> 689\u001b[0m y_ \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mf_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mf_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    690\u001b[0m _, (y_tensor_,) \u001b[38;5;241m=\u001b[39m disassemble_tree(y_, cache\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, attr_type\u001b[38;5;241m=\u001b[39mvalue_attributes)\n\u001b[1;32m    691\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mset\u001b[39m(non_batch(y_tensor_)) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mset\u001b[39m(non_batch(y_tensor)), \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFunction returned dimensions \u001b[39m\u001b[38;5;132;01m{\u001b[39;00my_tensor_\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m but right-hand-side has shape \u001b[39m\u001b[38;5;132;01m{\u001b[39;00my_tensor\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n",
      "Cell \u001b[0;32mIn[574], line 77\u001b[0m, in \u001b[0;36mtwo_phase_flow.phi_w_momentum_eq\u001b[0;34m(self, phi_w, phi_o, dt)\u001b[0m\n\u001b[1;32m     73\u001b[0m o_advection_term \u001b[38;5;241m=\u001b[39m dt \u001b[38;5;241m*\u001b[39m advect\u001b[38;5;241m.\u001b[39msemi_lagrangian((phi_w),\n\u001b[1;32m     74\u001b[0m                                                 \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_convective_velocity(phi_o,phi_w,dK_o),\n\u001b[1;32m     75\u001b[0m                                                 dt)\u001b[38;5;241m.\u001b[39msample(phi_w\u001b[38;5;241m.\u001b[39mgeometry)\n\u001b[1;32m     76\u001b[0m w_diffusion_term \u001b[38;5;241m=\u001b[39m dt \u001b[38;5;241m*\u001b[39m anisotropic_diffusion\u001b[38;5;241m.\u001b[39mimplicit(phi_w,K_w(p_c), dt\u001b[38;5;241m=\u001b[39mdt,correct_skew\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\u001b[38;5;241m.\u001b[39msample(phi_w\u001b[38;5;241m.\u001b[39mgeometry)\n\u001b[0;32m---> 77\u001b[0m o_diffusion_term \u001b[38;5;241m=\u001b[39m dt \u001b[38;5;241m*\u001b[39m \u001b[43manisotropic_diffusion\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimplicit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mphi_o\u001b[49m\u001b[43m,\u001b[49m\u001b[43mK_o\u001b[49m\u001b[43m(\u001b[49m\u001b[43mp_c\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdt\u001b[49m\u001b[43m,\u001b[49m\u001b[43mcorrect_skew\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39msample(phi_w\u001b[38;5;241m.\u001b[39mgeometry)\n\u001b[1;32m     79\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m phi_w \u001b[38;5;241m+\u001b[39m phi_w\u001b[38;5;241m.\u001b[39mwith_values(w_advection_term \u001b[38;5;241m+\u001b[39m o_advection_term) \u001b[38;5;241m+\u001b[39m phi_w\u001b[38;5;241m.\u001b[39mwith_values(w_diffusion_term \u001b[38;5;241m-\u001b[39m o_diffusion_term)\n",
      "File \u001b[0;32m~/PhysicsSimulationDeepLearning/Physical_models/anisotropic_diffusion.py:96\u001b[0m, in \u001b[0;36mimplicit\u001b[0;34m(field, diffusivity, dt, solve, gradient, upwind, correct_skew, gradient_for_diffusivity)\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m solve\u001b[38;5;241m.\u001b[39mx0:\n\u001b[1;32m     95\u001b[0m     solve \u001b[38;5;241m=\u001b[39m copy_with(solve, x0\u001b[38;5;241m=\u001b[39mfield)\n\u001b[0;32m---> 96\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msolve_linear\u001b[49m\u001b[43m(\u001b[49m\u001b[43msharpen\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfield\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msolve\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msolve\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_for_f\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgradient_for_diffusivity\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/phiml/math/_optimize.py:671\u001b[0m, in \u001b[0;36msolve_linear\u001b[0;34m(f, y, solve, grad_for_f, f_kwargs, *f_args, **f_kwargs_)\u001b[0m\n\u001b[1;32m    668\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m result  \u001b[38;5;66;03m# must return exactly `x` so gradient isn't computed w.r.t. other quantities\u001b[39;00m\n\u001b[1;32m    670\u001b[0m     _matrix_solve \u001b[38;5;241m=\u001b[39m attach_gradient_solve(_matrix_solve_forward, auxiliary_args\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mis_backprop,solve\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,matrix\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mif\u001b[39;00m\u001b[38;5;250m \u001b[39mmatrix\u001b[38;5;241m.\u001b[39mbackend\u001b[38;5;250m \u001b[39m\u001b[38;5;241m==\u001b[39m\u001b[38;5;250m \u001b[39mNUMPY\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01melse\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m, matrix_adjoint\u001b[38;5;241m=\u001b[39mgrad_for_f)\n\u001b[0;32m--> 671\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_matrix_solve\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msolve\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmatrix\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    672\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:  \u001b[38;5;66;03m# Matrix-free solve\u001b[39;00m\n\u001b[1;32m    673\u001b[0m     f_args \u001b[38;5;241m=\u001b[39m cached(f_args)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/phiml/math/_functional.py:963\u001b[0m, in \u001b[0;36mCustomGradientFunction.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    958\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraces) \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m8\u001b[39m:\n\u001b[1;32m    959\u001b[0m                 warnings\u001b[38;5;241m.\u001b[39mwarn(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m has been traced \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraces)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m times.\u001b[39m\n\u001b[1;32m    960\u001b[0m \u001b[38;5;124mTo avoid memory leaks, call \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mf_name(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.traces.clear(), \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mf_name(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.recorded_mappings.clear().\u001b[39m\n\u001b[1;32m    961\u001b[0m \u001b[38;5;124mTraces can be avoided by jit-compiling the code that calls custom gradient functions.\u001b[39m\n\u001b[1;32m    962\u001b[0m \u001b[38;5;124m\"\"\"\u001b[39m, \u001b[38;5;167;01mRuntimeWarning\u001b[39;00m, stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m--> 963\u001b[0m         native_result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraces\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mnatives\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# With PyTorch + jit, this does not call forward_native every time\u001b[39;00m\n\u001b[1;32m    964\u001b[0m         output_key \u001b[38;5;241m=\u001b[39m match_output_signature(key, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrecorded_mappings, \u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m    965\u001b[0m         output_tensors \u001b[38;5;241m=\u001b[39m assemble_tensors(native_result, output_key\u001b[38;5;241m.\u001b[39mspecs)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/phiml/backend/torch/_torch_backend.py:251\u001b[0m, in \u001b[0;36mTorchBackend.custom_gradient.<locals>.select_jit\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m    249\u001b[0m args \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mas_tensor(arg) \u001b[38;5;28;01mfor\u001b[39;00m arg \u001b[38;5;129;01min\u001b[39;00m args]\n\u001b[1;32m    250\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m CURRENT_JIT_CALLS:\n\u001b[0;32m--> 251\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    252\u001b[0m jit \u001b[38;5;241m=\u001b[39m CURRENT_JIT_CALLS[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m    253\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_get_tracing_state() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:  \u001b[38;5;66;03m# first call: record this function\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/function.py:575\u001b[0m, in \u001b[0;36mFunction.apply\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m    572\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_are_functorch_transforms_active():\n\u001b[1;32m    573\u001b[0m     \u001b[38;5;66;03m# See NOTE: [functorch vjp and autograd interaction]\u001b[39;00m\n\u001b[1;32m    574\u001b[0m     args \u001b[38;5;241m=\u001b[39m _functorch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39munwrap_dead_wrappers(args)\n\u001b[0;32m--> 575\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m    577\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_setup_ctx_defined:\n\u001b[1;32m    578\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    579\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIn order to use an autograd.Function with functorch transforms \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    580\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(vmap, grad, jvp, jacrev, ...), it must override the setup_context \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    581\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstaticmethod. For more details, please see \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    582\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://pytorch.org/docs/main/notes/extending.func.html\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    583\u001b[0m     )\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/phiml/backend/torch/_torch_backend.py:1206\u001b[0m, in \u001b[0;36mconstruct_torch_custom_function.<locals>.TorchCustomFunction.forward\u001b[0;34m(ctx, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1204\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m f_example_output\n\u001b[1;32m   1205\u001b[0m ML_LOGGER\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTorchScript -> run compiled \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mf\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m with args \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m[(\u001b[38;5;28mtuple\u001b[39m(a\u001b[38;5;241m.\u001b[39mshape),\u001b[38;5;250m \u001b[39ma\u001b[38;5;241m.\u001b[39mrequires_grad)\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mfor\u001b[39;00m\u001b[38;5;250m \u001b[39ma\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01min\u001b[39;00m\u001b[38;5;250m \u001b[39margs]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 1206\u001b[0m y \u001b[38;5;241m=\u001b[39m \u001b[43m(\u001b[49m\u001b[43mjit_f\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1207\u001b[0m ctx\u001b[38;5;241m.\u001b[39msave_for_backward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39my)\n\u001b[1;32m   1208\u001b[0m ctx\u001b[38;5;241m.\u001b[39minput_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(args)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/phiml/math/_functional.py:919\u001b[0m, in \u001b[0;36mCustomGradientFunction._trace.<locals>.forward_native\u001b[0;34m(*natives)\u001b[0m\n\u001b[1;32m    917\u001b[0m kwargs \u001b[38;5;241m=\u001b[39m assemble_tree(in_key\u001b[38;5;241m.\u001b[39mtree, in_tensors, attr_type\u001b[38;5;241m=\u001b[39mvariable_attributes)\n\u001b[1;32m    918\u001b[0m ML_LOGGER\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRunning forward pass of custom op \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mforward_native\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m given args \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtuple\u001b[39m(kwargs\u001b[38;5;241m.\u001b[39mkeys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m containing \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(natives)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m native tensors\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 919\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43min_key\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mauxiliary_kwargs\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Tensor or tuple/list of Tensors\u001b[39;00m\n\u001b[1;32m    920\u001b[0m nest, out_tensors \u001b[38;5;241m=\u001b[39m disassemble_tree(result, cache\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, attr_type\u001b[38;5;241m=\u001b[39mvariable_attributes)\n\u001b[1;32m    921\u001b[0m result_natives, result_shapes, specs \u001b[38;5;241m=\u001b[39m disassemble_tensors(out_tensors, expand\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/phiml/math/_optimize.py:667\u001b[0m, in \u001b[0;36msolve_linear.<locals>._matrix_solve_forward\u001b[0;34m(y, solve, matrix, is_backprop)\u001b[0m\n\u001b[1;32m    665\u001b[0m     idx \u001b[38;5;241m=\u001b[39m b\u001b[38;5;241m.\u001b[39mconcat([idx, new_col, new_row], \u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m    666\u001b[0m     nat_matrix \u001b[38;5;241m=\u001b[39m b\u001b[38;5;241m.\u001b[39msparse_coo_tensor(idx, data, (N\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m, N\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m))\n\u001b[0;32m--> 667\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43m_linear_solve_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msolve\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnat_matrix\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpattern_dims_in\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpattern_dims_out\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreconditioner\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbackend\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_backprop\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    668\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/phiml/math/_optimize.py:780\u001b[0m, in \u001b[0;36m_linear_solve_forward\u001b[0;34m(y, solve, native_lin_op, pattern_dims_in, pattern_dims_out, preconditioner, backend, is_backprop)\u001b[0m\n\u001b[1;32m    778\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m tape \u001b[38;5;129;01min\u001b[39;00m _SOLVE_TAPES:\n\u001b[1;32m    779\u001b[0m     tape\u001b[38;5;241m.\u001b[39m_add(solve, trj, result)\n\u001b[0;32m--> 780\u001b[0m \u001b[43mresult\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvergence_check\u001b[49m\u001b[43m(\u001b[49m\u001b[43mis_backprop\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mand\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mTensorFlow\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbackend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# raises ConvergenceException\u001b[39;00m\n\u001b[1;32m    781\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m final_x\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/phiml/math/_optimize.py:208\u001b[0m, in \u001b[0;36mSolveInfo.convergence_check\u001b[0;34m(self, only_warn)\u001b[0m\n\u001b[1;32m    206\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmsg, ConvergenceWarning)\n\u001b[1;32m    207\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 208\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m NotConverged(\u001b[38;5;28mself\u001b[39m)\n",
      "\u001b[0;31mNotConverged\u001b[0m: Φ-ML CG (PyTorch*) did not converge to rel_tol=1e-05, abs_tol=1e-05 within 1000 iterations. Max residual: nan"
     ]
    }
   ],
   "source": [
    "for i in range(1):\n",
    "    phi=phy.implicit_time_step(*phi,1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m(xˢ=64, yˢ=64)\u001b[0m \u001b[94m-0.774 ± 5.948\u001b[0m \u001b[37m(-5e+01...0e+00)\u001b[0m\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m(xˢ=64, yˢ=64)\u001b[0m \u001b[94mconst 0.0\u001b[0m\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m(xˢ=64, yˢ=64)\u001b[0m \u001b[94m0.595 ± 0.127\u001b[0m \u001b[37m(3e-01...6e-01)\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[92m(xˢ=64, yˢ=64)\u001b[0m \u001b[94m-0.774 ± 5.948\u001b[0m \u001b[37m(-5e+01...0e+00)\u001b[0m"
      ]
     },
     "execution_count": 562,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(phi[0].sample(geo_w))\n",
    "plt.imshow(phi[0].sample(geo_w).native(\"x,y\"))\n",
    "plt.show()\n",
    "print(phi[1].sample(geo_w))\n",
    "plt.imshow(phi[1].sample(geo_o).native(\"x,y\"))\n",
    "plt.show()\n",
    "plt.imshow(S_w(phy.compute_p_c(*phi)))\n",
    "print(S_w(phy.compute_p_c(*phi)))\n",
    "\n",
    "phy.compute_p_c(*phi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 568,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.3000, 0.3000, 0.3000,  ..., 0.3000, 0.3000, 0.3000],\n",
      "        [0.3000, 0.3000, 0.3000,  ..., 0.3000, 0.3000, 0.3000],\n",
      "        [0.3000, 0.3000, 0.3000,  ..., 0.3000, 0.3000, 0.3000],\n",
      "        ...,\n",
      "        [0.6500, 0.6500, 0.6500,  ..., 0.6500, 0.6500, 0.6500],\n",
      "        [0.6500, 0.6500, 0.6500,  ..., 0.6500, 0.6500, 0.6500],\n",
      "        [0.6500, 0.6500, 0.6500,  ..., 0.6500, 0.6500, 0.6500]])\n"
     ]
    }
   ],
   "source": [
    "print(S_w(phy.compute_p_c(*phi)).native(\"x,y\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grandient example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[1., 1., 1.]],\n",
      "\n",
      "        [[1., 1., 1.]],\n",
      "\n",
      "        [[1., 1., 1.]]], requires_grad=True)\n",
      "tensor([[[1.0000, 1.8415, 0.5403, 1.0000]],\n",
      "\n",
      "        [[1.0000, 1.8415, 0.5403, 1.0000]],\n",
      "\n",
      "        [[1.0000, 1.8415, 0.5403, 1.0000]]], grad_fn=<StackBackward0>)\n",
      "torch.Size([3, 1, 4])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([[[0.1585, 2.5403, 0.0000]],\n",
       " \n",
       "         [[0.1585, 2.5403, 0.0000]],\n",
       " \n",
       "         [[0.1585, 2.5403, 0.0000]]], grad_fn=<AddBackward0>),)"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1 = torch.ones((3,1,3)).requires_grad_(True)  #\n",
    "print(x1)\n",
    "\n",
    "u1 = torch.stack([\n",
    "    x1[:,:,0]**0.5,\n",
    "    torch.sin(x1[:,:,1])+x1[:,:,0]**0.5,\n",
    "    torch.cos(x1[:,:,0]),\n",
    "    x1[:,:,1]**2,\n",
    "    ],axis=2)\n",
    "\n",
    "#u1 = torch.matmul(M,x1)\n",
    "\n",
    "\n",
    "#u1=torch.sin(torch.matmul(torch.rand(2,2).requires_grad_(True),x1))\n",
    "print(u1)\n",
    "print(u1.shape)\n",
    "torch.autograd.grad(\n",
    "    u1,x1,\n",
    "            grad_outputs=torch.ones_like(u1).to(u1.device),\n",
    "            create_graph=True,\n",
    "            retain_graph=True,\n",
    "            allow_unused=True\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Jacobian computation\n",
    "\n",
    "Expressed in pytorch with torch.autograd.grad\n",
    "\n",
    "$$ \\textbf{u} \\in \\mathbb{R}^n \\\\ \\textbf{x},\\textbf{e}_i \\in \\mathbb{R}^m $$\n",
    "$$ T_{ag} (\\textbf{u},\\textbf{x},\\textbf{e}_i) = \\nabla_{\\textbf{x}} \\textbf{u}_i  $$\n",
    "$$ T_{ag} (\\textbf{u},\\textbf{x},\\textbf{e}_i) = \\nabla_{\\textbf{x}} \\textbf{u}_i  $$\n",
    "$$ T_{ag} (\\textbf{u},\\textbf{x},\\textbf{e}_i+\\textbf{e}_j) = \\nabla_{\\textbf{x}} \\textbf{u}_i + \\nabla_{\\textbf{x}} \\textbf{u}_j $$\n",
    "$$ [T_{ag} (\\textbf{u},\\textbf{x},\\textbf{e}_i)]_{i=1}^n = J_{\\textbf{x}}(\\textbf{u})$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[1.0000, 1.8415, 0.5403, 1.0000]],\n",
      "\n",
      "        [[1.0000, 1.8415, 0.5403, 1.0000]],\n",
      "\n",
      "        [[1.0000, 1.8415, 0.5403, 1.0000]]], grad_fn=<StackBackward0>)\n",
      "[tensor([[[0.5000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.5000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.5000, 0.0000, 0.0000]]], grad_fn=<AddBackward0>), tensor([[[0.5000, 0.5403, 0.0000]],\n",
      "\n",
      "        [[0.5000, 0.5403, 0.0000]],\n",
      "\n",
      "        [[0.5000, 0.5403, 0.0000]]], grad_fn=<AddBackward0>), tensor([[[-0.8415,  0.0000,  0.0000]],\n",
      "\n",
      "        [[-0.8415,  0.0000,  0.0000]],\n",
      "\n",
      "        [[-0.8415,  0.0000,  0.0000]]], grad_fn=<AddBackward0>), tensor([[[0., 2., 0.]],\n",
      "\n",
      "        [[0., 2., 0.]],\n",
      "\n",
      "        [[0., 2., 0.]]], grad_fn=<AddBackward0>)]\n",
      "tensor([[[[ 0.5000,  0.0000,  0.0000],\n",
      "          [ 0.5000,  0.5403,  0.0000],\n",
      "          [-0.8415,  0.0000,  0.0000],\n",
      "          [ 0.0000,  2.0000,  0.0000]]],\n",
      "\n",
      "\n",
      "        [[[ 0.5000,  0.0000,  0.0000],\n",
      "          [ 0.5000,  0.5403,  0.0000],\n",
      "          [-0.8415,  0.0000,  0.0000],\n",
      "          [ 0.0000,  2.0000,  0.0000]]],\n",
      "\n",
      "\n",
      "        [[[ 0.5000,  0.0000,  0.0000],\n",
      "          [ 0.5000,  0.5403,  0.0000],\n",
      "          [-0.8415,  0.0000,  0.0000],\n",
      "          [ 0.0000,  2.0000,  0.0000]]]], grad_fn=<StackBackward0>)\n",
      "torch.Size([3, 1, 4, 3])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 1, 3])"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unit_vectors=torch.eye(4)\n",
    "print(u1)\n",
    "jacobian_rows = [torch.autograd.grad(u1, x1, vec_.unsqueeze(0).unsqueeze(0).tile(u1.shape[0],u1.shape[1],1),\n",
    "            create_graph=True,\n",
    "            retain_graph=True,\n",
    "            allow_unused=True)[0]\n",
    "                     for vec_ in unit_vectors]\n",
    "print(jacobian_rows)\n",
    "print(torch.stack(jacobian_rows,axis=2))\n",
    "print(torch.stack(jacobian_rows,axis=2).shape)\n",
    "\n",
    "torch.autograd.grad(u1, x1, unit_vectors[1].unsqueeze(0).unsqueeze(0).tile(u1.shape[0],u1.shape[1],1),\n",
    "            create_graph=True,\n",
    "            retain_graph=True,\n",
    "            allow_unused=True)[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "\n",
    "def vector_jacobian(u,x):\n",
    "    unit_vectors=torch.eye(u.shape[-1])\n",
    "    jacobian_rows = [torch.autograd.grad(u, x, vec_.unsqueeze(0).unsqueeze(0).tile(u.shape[0],u.shape[1],1),\n",
    "            create_graph=True,\n",
    "            retain_graph=True,\n",
    "            allow_unused=True)[0]\n",
    "                     for vec_ in unit_vectors]\n",
    "    return torch.stack(jacobian_rows,axis=2)\n",
    "\n",
    "\n",
    "def vector_grad(u,x):\n",
    "    unit_vectors=torch.eye(u.shape[-1])\n",
    "    jacobian_rows = [torch.autograd.grad(u, x, vec_.unsqueeze(0).unsqueeze(0).tile(u.shape[0],u.shape[1],1),\n",
    "            create_graph=True,\n",
    "            retain_graph=True,\n",
    "            allow_unused=True)[0]\n",
    "                     for vec_ in unit_vectors]\n",
    "    return torch.diagonal(torch.stack(jacobian_rows,axis=2),dim1=-2,dim2=-1)\n",
    "\n",
    "def x_grad(u,x,i,n):\n",
    "    \"\"\"\n",
    "    gradient of degree wrt x for componen i for u\n",
    "    input:\n",
    "    u and x are tensors with vectors object at dimension -1\n",
    "    [b, n_vectors, vector_dimension]\n",
    "\n",
    "    output:\n",
    "    [b, n_vectors, input_vector_dimension]\n",
    "    \"\"\"\n",
    "    I=torch.eye(u.shape[-1])\n",
    "\n",
    "    u=torch.autograd.grad(u ,x,\n",
    "            I[i].unsqueeze(0).unsqueeze(0).tile(u.shape[0],u.shape[1],1).to(u.device),\n",
    "            create_graph=True,\n",
    "            retain_graph=True,\n",
    "            allow_unused=True)[0]\n",
    "    if n > 1:\n",
    "        for i in range(n-1):\n",
    "            u=vector_grad(u,x)\n",
    "    return u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.5000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.5000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.5000, 0.0000, 0.0000]]], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(x_grad(u1,x1,0,1))\n",
    "udx=x_grad(u1,x1,0,1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 1, 3])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[1., 1., 1.]],\n",
       "\n",
       "        [[1., 1., 1.]],\n",
       "\n",
       "        [[1., 1., 1.]]], requires_grad=True)"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(x1.shape)\n",
    "x1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.5000],\n",
       "        [0.5000],\n",
       "        [0.5000]], grad_fn=<SumBackward1>)"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sum(x1*udx,axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.5000, 0.0000]],\n",
       "\n",
       "        [[0.5000, 0.0000]],\n",
       "\n",
       "        [[0.5000, 0.0000]]], grad_fn=<SliceBackward0>)"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "udx[:,:,:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Residuals debug"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NS reesidual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def incompresibble_fluid_loss(up,xt,mu=1,rho=1):\n",
    "    l=0\n",
    "    # x-velocity components\n",
    "    l+=x_grad(up,xt,0,1)[...,2] # dudt\n",
    "    l+=torch.sum(up[...,:1]*x_grad(up,xt,0,1)[...,:2],axis=-1) # u * grad u\n",
    "    l+=(mu/rho)*(x_grad(up,xt,2,1)[...,0]) #  dpdx\n",
    "    l-=(mu/rho)*torch.sum(x_grad(up,xt,0,2)[...,:2],axis=-1) # grad**2 u\n",
    "    # y-velocity components\n",
    "    l+=x_grad(up,xt,1,1)[...,2] # dvdt\n",
    "    l+=torch.sum(up[...,1:2]*x_grad(up,xt,0,1)[...,:2],axis=-1) # v * grad v\n",
    "    l+=(mu/rho)*(x_grad(up,xt,2,1)[...,1]) #  dpdy\n",
    "    l-=(mu/rho)*torch.sum(x_grad(up,xt,1,2)[...,:2],axis=-1) # grad**2 v\n",
    "    return l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-1.5316, -0.0218,  1.3527]],\n",
      "\n",
      "        [[ 2.0246,  0.5625, -0.8633]],\n",
      "\n",
      "        [[ 0.5488, -0.9313,  0.3730]]], requires_grad=True)\n",
      "torch.Size([3, 1, 3])\n",
      "torch.Size([3, 1, 3])\n"
     ]
    }
   ],
   "source": [
    "x1 = torch.randn((3,1,3)).requires_grad_(True)  #\n",
    "print(x1)\n",
    "print(x1.shape)\n",
    "\n",
    "u1 = torch.stack([\n",
    "    x1[:,:,0]**0.5,\n",
    "    torch.sin(x1[:,:,1])+x1[:,:,0]**0.5,\n",
    "    torch.cos(x1[:,:,0]),\n",
    "    ],axis=2)\n",
    "\n",
    "print(u1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[   nan],\n",
       "        [0.9955],\n",
       "        [0.3642]], grad_fn=<SubBackward0>)"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "incompresibble_fluid_loss(u1,x1,1,1)-0\n",
    "#x_grad(u1,x1,0,1)[...,0]\n",
    "#print(x1[:,:,:1])\n",
    "#print(x_grad(u1,x1,0,1)[...,:2])\n",
    "#x_grad(u1,x1,0,1)[...,2]\n",
    "#x_grad(u1,x1,0,2)[...,:2]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
